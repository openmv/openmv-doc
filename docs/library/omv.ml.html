

<!DOCTYPE html>
<html class="writer-html5" lang="en">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>ml — Machine Learning &mdash; MicroPython 1.24 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=03e43079" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../_static/custom.css?v=d5a28fe3" />
      <link rel="stylesheet" href="../_static/customstyle.css" type="text/css" />

  
    <link rel="shortcut icon" href="../_static/openmv.ico"/>
      <script src="../_static/jquery.js?v=5d32c60e"></script>
      <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js?v=97333489"></script>
      <script src="../_static/doctools.js?v=888ff710"></script>
      <script src="../_static/sphinx_highlight.js?v=4825356b"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="ml.apps — ML Apps" href="omv.ml.apps.html" />
    <link rel="prev" title="image — machine vision" href="omv.image.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            MicroPython
              <img src="../_static/web-logo-sticky.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="index.html">MicroPython libraries</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="index.html#python-standard-libraries-and-micro-libraries">Python standard libraries and micro-libraries</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#micropython-specific-libraries">MicroPython-specific libraries</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="index.html#libraries-specific-to-the-openmv-cam">Libraries specific to the OpenMV Cam</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="pyb.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">pyb</span></code> — functions related to the board</a></li>
<li class="toctree-l3"><a class="reference internal" href="stm.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">stm</span></code> — functionality specific to STM32 MCUs</a></li>
<li class="toctree-l3"><a class="reference internal" href="omv.sensor.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sensor</span></code> — camera sensor</a></li>
<li class="toctree-l3"><a class="reference internal" href="omv.image.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">image</span></code> — machine vision</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#"><code class="xref py py-mod docutils literal notranslate"><span class="pre">ml</span></code> — Machine Learning</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#sub-modules">Sub Modules</a></li>
<li class="toctree-l4"><a class="reference internal" href="#class-model-model-container">class model – Model Container</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="omv.gif.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">gif</span></code> — gif recording</a></li>
<li class="toctree-l3"><a class="reference internal" href="omv.mjpeg.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">mjpeg</span></code> — mjpeg recording</a></li>
<li class="toctree-l3"><a class="reference internal" href="omv.audio.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">audio</span></code> — Audio Module</a></li>
<li class="toctree-l3"><a class="reference internal" href="omv.display.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">display</span></code> — display driver</a></li>
<li class="toctree-l3"><a class="reference internal" href="omv.fir.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">fir</span></code> — thermal sensor driver (fir == far infrared)</a></li>
<li class="toctree-l3"><a class="reference internal" href="omv.tof.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tof</span></code> — time-of-flight sensor driver</a></li>
<li class="toctree-l3"><a class="reference internal" href="omv.tv.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tv</span></code> — tv shield driver</a></li>
<li class="toctree-l3"><a class="reference internal" href="omv.cpufreq.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">cpufreq</span></code> — CPU Frequency Control</a></li>
<li class="toctree-l3"><a class="reference internal" href="omv.buzzer.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">buzzer</span></code> — buzzer driver</a></li>
<li class="toctree-l3"><a class="reference internal" href="omv.imu.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">imu</span></code> — imu sensor</a></li>
<li class="toctree-l3"><a class="reference internal" href="omv.rpc.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">rpc</span></code> — rpc library</a></li>
<li class="toctree-l3"><a class="reference internal" href="omv.rtsp.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">rtsp</span></code> — rtsp library</a></li>
<li class="toctree-l3"><a class="reference internal" href="omv.omv.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">omv</span></code> — OpenMV Cam Information</a></li>
<li class="toctree-l3"><a class="reference internal" href="omv.gt911.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">gt911</span></code> — Touch Screen Driver</a></li>
<li class="toctree-l3"><a class="reference internal" href="omv.ft5x06.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">ft5x06</span></code> — Touch Screen Driver</a></li>
<li class="toctree-l3"><a class="reference internal" href="omv.tfp410.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tfp410</span></code> — DVI/HDMI Controller</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="index.html#third-party-libraries-on-the-openmv-cam">Third-party libraries on the OpenMV Cam</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#extending-built-in-libraries-from-python">Extending built-in libraries from Python</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../reference/index.html">MicroPython language and implementation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../genrst/index.html">MicroPython differences from CPython</a></li>
<li class="toctree-l1"><a class="reference internal" href="../license.html">MicroPython license information</a></li>
<li class="toctree-l1"><a class="reference internal" href="../openmvcam/quickref.html">Quick reference for the openmvcam</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MicroPython</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="index.html">MicroPython libraries</a></li>
      <li class="breadcrumb-item active"><code class="xref py py-mod docutils literal notranslate"><span class="pre">ml</span></code> — Machine Learning</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/library/omv.ml.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="module-ml">
<span id="ml-machine-learning"></span><h1><a class="reference internal" href="#module-ml" title="ml: Machine Learning"><code class="xref py py-mod docutils literal notranslate"><span class="pre">ml</span></code></a> — Machine Learning<a class="headerlink" href="#module-ml" title="Permalink to this heading">¶</a></h1>
<p>The <a class="reference internal" href="#module-ml" title="ml: Machine Learning"><code class="xref any py py-mod docutils literal notranslate"><span class="pre">ml</span></code></a> module contains functionality for processing machine learning models on the OpenMV Cam.</p>
<p>The heart of the <a class="reference internal" href="#module-ml" title="ml: Machine Learning"><code class="xref any py py-mod docutils literal notranslate"><span class="pre">ml</span></code></a> module is the <a class="reference internal" href="#ml.Model" title="ml.Model"><code class="xref any py py-class docutils literal notranslate"><span class="pre">Model()</span></code></a> object which is used to load and execute
TensorFlow Lite models. The <a class="reference internal" href="#ml.Model" title="ml.Model"><code class="xref any py py-class docutils literal notranslate"><span class="pre">Model()</span></code></a> object accepts a list of up to 4D input tensors for
each model input tensor and returns a list of up to 4D output tensors for each model output
tensor. Each input/output tensor works using a numpy <code class="docutils literal notranslate"><span class="pre">ndarray</span></code>.</p>
<p>For TensorFlow Lite models, the <a class="reference internal" href="#ml.Model" title="ml.Model"><code class="xref any py py-class docutils literal notranslate"><span class="pre">Model()</span></code></a> object handles all ops enabled
<a class="reference external" href="https://github.com/openmv/openmv/blob/master/src/lib/tflm/tflm_backend.cc">here</a>. The <a class="reference internal" href="#ml.Model" title="ml.Model"><code class="xref any py py-class docutils literal notranslate"><span class="pre">Model()</span></code></a>
object will automatically leverage CMSIS-NN, Helium, and an Ethos NPU if available to speed up
inference. Availability of these accelerators is dependent on the OpenMV Cam model.</p>
<p>For image processing support the <a class="reference internal" href="#module-ml" title="ml: Machine Learning"><code class="xref any py py-mod docutils literal notranslate"><span class="pre">ml</span></code></a> module automatically converts passed image objects to numpy
<code class="docutils literal notranslate"><span class="pre">ndarray</span></code> objects by wrapping them with the <a class="reference internal" href="omv.ml.preprocessing.html#ml.preprocessing.Normalization" title="ml.preprocessing.Normalization"><code class="xref any py py-class docutils literal notranslate"><span class="pre">Normalization()</span></code></a> object which handles this conversion. The
<a class="reference internal" href="omv.ml.preprocessing.html#ml.preprocessing.Normalization" title="ml.preprocessing.Normalization"><code class="xref any py py-class docutils literal notranslate"><span class="pre">Normalization()</span></code></a> object can also be manually created to control the conversion process, select an
ROI, and etc.</p>
<p>For more information on <code class="docutils literal notranslate"><span class="pre">ndarray</span></code> objects see the
<a class="reference external" href="https://micropython-ulab.readthedocs.io/en/latest/">ulab documentation</a>. All OpenMV Cams support
ndarray objects up to rank 4 (meaning 4D tensors).</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Complex number support and the <a class="reference external" href="https://micropython-ulab.readthedocs.io/en/latest/scipy-special.html">scipy special module</a>
are currently disabled on all OpenMV Cams at the moment to save flash space.</p>
</div>
<section id="sub-modules">
<h2>Sub Modules<a class="headerlink" href="#sub-modules" title="Permalink to this heading">¶</a></h2>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="omv.ml.apps.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">ml.apps</span></code> — ML Apps</a><ul>
<li class="toctree-l2"><a class="reference internal" href="omv.ml.apps.html#class-microspeech-speech-recognition">class MicroSpeech – Speech Recognition</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="omv.ml.preprocessing.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">ml.preprocessing</span></code> — ML Preprocessing</a><ul>
<li class="toctree-l2"><a class="reference internal" href="omv.ml.preprocessing.html#class-normalization-image-normalization">class Normalization – Image Normalization</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="omv.ml.postprocessing.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">ml.postprocessing</span></code> — ML Postprocessing</a><ul>
<li class="toctree-l2"><a class="reference internal" href="omv.ml.postprocessing.html#class-fomo-postprocess-fomo">class fomo_postprocess – FOMO</a></li>
<li class="toctree-l2"><a class="reference internal" href="omv.ml.postprocessing.html#class-yolo-v2-postprocess-yolo-v2">class yolo_v2_postprocess – YOLO V2</a></li>
<li class="toctree-l2"><a class="reference internal" href="omv.ml.postprocessing.html#class-yolo-v5-postprocess-yolo-v5">class yolo_v5_postprocess – YOLO V5</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="omv.ml.utils.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">ml.utils</span></code> — ML Utils</a><ul>
<li class="toctree-l2"><a class="reference internal" href="omv.ml.utils.html#class-nms-soft-non-maximum-suppression">class NMS - Soft-Non-Maximum Suppression</a></li>
</ul>
</li>
</ul>
</div>
</section>
<section id="class-model-model-container">
<h2>class model – Model Container<a class="headerlink" href="#class-model-model-container" title="Permalink to this heading">¶</a></h2>
<p>A model object is used to load and execute TensorFlow Lite models. The model object accepts a list
of up to 4D input tensors per model corresponding to the number of tensor inputs of the model
and returns a list of up to 4D output tensors corresponding to the number of tensor outputs of the
model. Each input/output tensor is an numpy <code class="docutils literal notranslate"><span class="pre">ndarray</span></code>.</p>
<section id="constructors">
<h3>Constructors<a class="headerlink" href="#constructors" title="Permalink to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="ml.Model">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ml.</span></span><span class="sig-name descname"><span class="pre">Model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="builtins.html#str" title="str"><span class="pre">str</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">load_to_fb</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="builtins.html#bool" title="bool"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#ml.Model" title="ml.Model"><span class="pre">Model</span></a></span></span><a class="headerlink" href="#ml.Model" title="Permalink to this definition">¶</a></dt>
<dd><p>Loads a model from <code class="docutils literal notranslate"><span class="pre">path</span></code> into memory and prepares it for being executed. <code class="docutils literal notranslate"><span class="pre">path</span></code> can either
be a file on disk or the name of a built-in model which will be loaded from internal flash. Models that are
built-in to the internal flash firmware image do not take up RAM to store the model weights when used.</p>
<p>If the model you are trying to load is very large and doesn’t fit in the MicroPython heap you
can set <code class="docutils literal notranslate"><span class="pre">load_to_fb</span></code> to True to load the model into the frame buffer stack instead. This allows
you to get around the heap size limitations. However, models loaded this way need to be deallocated
in-order with anything else that uses the frame buffer stack versus the MicroPython heap. Typically,
the frame buffer stack is much larger than the MicroPython heap so you can load much larger models
using this option, but, you need to be careful if you deallocate.</p>
<p>Once a model is loaded you can execute it multiple times with different inputs using <a class="reference internal" href="#ml.Model.predict" title="ml.Model.predict"><code class="xref any py py-meth docutils literal notranslate"><span class="pre">predict()</span></code></a>.
The model will rember its internal state between calls to <a class="reference internal" href="#ml.Model.predict" title="ml.Model.predict"><code class="xref any py py-meth docutils literal notranslate"><span class="pre">predict()</span></code></a>.</p>
<p>When deleted the model will automatically free up any memory it used from the heap or frame buffer stack.</p>
<section id="methods">
<h4>Methods<a class="headerlink" href="#methods" title="Permalink to this heading">¶</a></h4>
<dl class="py method">
<dt class="sig sig-object py" id="ml.Model.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="builtins.html#list" title="list"><span class="pre">list</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">callback</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="builtins.html#list" title="list"><span class="pre">list</span></a></span></span><a class="headerlink" href="#ml.Model.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Executes the model with the given inputs. The inputs should be a list of numpy <code class="docutils literal notranslate"><span class="pre">ndarray</span></code> objects corresponding
to the number of input tensors the model supports. The method returns a list of numpy <code class="docutils literal notranslate"><span class="pre">ndarray</span></code> objects
corresponding to the number of output tensors the model has.</p>
<p>The model input tensors can be up to 4D tensors of uint8, int8, int16, or float32 values. The passed
numpy <code class="docutils literal notranslate"><span class="pre">ndarray</span></code> for an input tensor is then converted to floating point and scaled/offset based on
the input tensor’s scale and zero point values before being passed to the model. For example, an <code class="docutils literal notranslate"><span class="pre">ndarray</span></code>
of uint8 values will be converted to float32s between 0.0-255.0, divided by the input tensor’s scale, and
then have the input tensor’s zero point added to it. The same process is done for int8 and int16 values
whereas float32 values are passed directly to the model ignoring the scale and zero point values.</p>
<p>The model’s output tensors can be up to 4D tensors of uint8, int8, or float32 values. For uint8
and int8 tensors the returned numpy ndarray is created by subtracting the output tensor’s zero
point value before multiplying by the output tensor’s scale value. For float32 tensors, values are
passed directly to the output without any scaling or offset being applied.</p>
<p>Note that <a class="reference internal" href="#ml.Model.predict" title="ml.Model.predict"><code class="xref any py py-meth docutils literal notranslate"><span class="pre">predict()</span></code></a> requires the shape of the input <code class="docutils literal notranslate"><span class="pre">ndarray</span></code> objects to match the shape of the model
input tensors exactly. You can use the <code class="docutils literal notranslate"><span class="pre">reshape()</span></code> method of an ndarray with the <a class="reference internal" href="#ml.Model.input_shape" title="ml.Model.input_shape"><code class="xref any py py-attr docutils literal notranslate"><span class="pre">input_shape</span></code></a>
attribute of the model to reshape the input data to the correct shape if necessary.</p>
<p>If a <code class="docutils literal notranslate"><span class="pre">callback</span></code> is passed then it will receive the <a class="reference internal" href="#ml.Model" title="ml.Model"><code class="xref any py py-class docutils literal notranslate"><span class="pre">Model</span></code></a>, <code class="docutils literal notranslate"><span class="pre">inputs</span></code>, and <code class="docutils literal notranslate"><span class="pre">outputs</span></code> as arguments
which allows for custom post-processing of the model outputs. The callback may then return
whatever it likes which will be returned by <a class="reference internal" href="#ml.Model.predict" title="ml.Model.predict"><code class="xref any py py-meth docutils literal notranslate"><span class="pre">predict()</span></code></a>. The <code class="docutils literal notranslate"><span class="pre">callback</span></code> method allows for building
up a library of post-processing functions that can be used on demand for different models.</p>
<p>For custom pre-processing, <a class="reference internal" href="#ml.Model.predict" title="ml.Model.predict"><code class="xref any py py-meth docutils literal notranslate"><span class="pre">predict()</span></code></a> also accepts “callable” objects as inputs. Any object
implementing the <code class="docutils literal notranslate"><span class="pre">__call__</span></code> method can be passed to <a class="reference internal" href="#ml.Model.predict" title="ml.Model.predict"><code class="xref any py py-meth docutils literal notranslate"><span class="pre">predict()</span></code></a> as an input. <a class="reference internal" href="#ml.Model.predict" title="ml.Model.predict"><code class="xref any py py-meth docutils literal notranslate"><span class="pre">predict()</span></code></a> will
then call the object with a writeable bytearray representing the input tensor, the input tensor’s shape tuple,
and the input tensors data type value (as an int). The object should then set the input tensor data in the
bytearray to what the model expects. This is how <a class="reference internal" href="omv.ml.preprocessing.html#ml.preprocessing.Normalization" title="ml.preprocessing.Normalization"><code class="xref any py py-class docutils literal notranslate"><span class="pre">Normalization()</span></code></a> converts image objects to input tensors.</p>
</dd></dl>

</section>
<section id="attributes">
<h4>Attributes<a class="headerlink" href="#attributes" title="Permalink to this heading">¶</a></h4>
<dl class="py attribute">
<dt class="sig sig-object py" id="ml.Model.len">
<span class="sig-name descname"><span class="pre">len</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="builtins.html#int" title="int"><span class="pre">int</span></a></em><a class="headerlink" href="#ml.Model.len" title="Permalink to this definition">¶</a></dt>
<dd><p>The size of the loaded model in bytes.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="ml.Model.ram">
<span class="sig-name descname"><span class="pre">ram</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="builtins.html#int" title="int"><span class="pre">int</span></a></em><a class="headerlink" href="#ml.Model.ram" title="Permalink to this definition">¶</a></dt>
<dd><p>The amount of RAM used by the model for it’s tensor arena.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="ml.Model.input_shape">
<span class="sig-name descname"><span class="pre">input_shape</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="builtins.html#list" title="list"><span class="pre">list</span></a><span class="p"><span class="pre">[</span></span><a class="reference internal" href="builtins.html#tuple" title="tuple"><span class="pre">tuple</span></a><span class="p"><span class="pre">[</span></span><a class="reference internal" href="builtins.html#int" title="int"><span class="pre">int</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#ml.Model.input_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>A list of tuples containing the shape of each input tensor.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="ml.Model.input_dtype">
<span class="sig-name descname"><span class="pre">input_dtype</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="builtins.html#list" title="list"><span class="pre">list</span></a><span class="p"><span class="pre">[</span></span><a class="reference internal" href="builtins.html#str" title="str"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#ml.Model.input_dtype" title="Permalink to this definition">¶</a></dt>
<dd><p>A list of strings containing the data type of each input tensor.
‘b’, ‘B’, ‘h’, and ‘f’ respectively for uint8, int8, int16, and float32.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="ml.Model.input_scale">
<span class="sig-name descname"><span class="pre">input_scale</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="builtins.html#list" title="list"><span class="pre">list</span></a><span class="p"><span class="pre">[</span></span><a class="reference internal" href="builtins.html#float" title="float"><span class="pre">float</span></a><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#ml.Model.input_scale" title="Permalink to this definition">¶</a></dt>
<dd><p>A list of floats containing the scale of each input tensor.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="ml.Model.input_zero_point">
<span class="sig-name descname"><span class="pre">input_zero_point</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="builtins.html#list" title="list"><span class="pre">list</span></a><span class="p"><span class="pre">[</span></span><a class="reference internal" href="builtins.html#int" title="int"><span class="pre">int</span></a><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#ml.Model.input_zero_point" title="Permalink to this definition">¶</a></dt>
<dd><p>A list of integers containing the zero point of each input tensor.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="ml.Model.output_shape">
<span class="sig-name descname"><span class="pre">output_shape</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="builtins.html#list" title="list"><span class="pre">list</span></a><span class="p"><span class="pre">[</span></span><a class="reference internal" href="builtins.html#tuple" title="tuple"><span class="pre">tuple</span></a><span class="p"><span class="pre">[</span></span><a class="reference internal" href="builtins.html#int" title="int"><span class="pre">int</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#ml.Model.output_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>A list of tuples containing the shape of each output tensor.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="ml.Model.output_dtype">
<span class="sig-name descname"><span class="pre">output_dtype</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="builtins.html#list" title="list"><span class="pre">list</span></a><span class="p"><span class="pre">[</span></span><a class="reference internal" href="builtins.html#str" title="str"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#ml.Model.output_dtype" title="Permalink to this definition">¶</a></dt>
<dd><p>A list of strings containing the data type of each output tensor.
‘b’, ‘B’ and ‘f’ respectively for uint8, int8 and float32.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="ml.Model.output_scale">
<span class="sig-name descname"><span class="pre">output_scale</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="builtins.html#list" title="list"><span class="pre">list</span></a><span class="p"><span class="pre">[</span></span><a class="reference internal" href="builtins.html#float" title="float"><span class="pre">float</span></a><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#ml.Model.output_scale" title="Permalink to this definition">¶</a></dt>
<dd><p>A list of floats containing the scale of each output tensor.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="ml.Model.output_zero_point">
<span class="sig-name descname"><span class="pre">output_zero_point</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="builtins.html#list" title="list"><span class="pre">list</span></a><span class="p"><span class="pre">[</span></span><a class="reference internal" href="builtins.html#int" title="int"><span class="pre">int</span></a><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#ml.Model.output_zero_point" title="Permalink to this definition">¶</a></dt>
<dd><p>A list of integers containing the zero point of each output tensor.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="ml.Model.labels">
<span class="sig-name descname"><span class="pre">labels</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="builtins.html#list" title="list"><span class="pre">list</span></a><span class="p"><span class="pre">[</span></span><a class="reference internal" href="builtins.html#str" title="str"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#ml.Model.labels" title="Permalink to this definition">¶</a></dt>
<dd><p>A list of strings containing the labels for the model (if it was built-in to the firmware with labels,
otherwise, <code class="docutils literal notranslate"><span class="pre">None</span></code>).</p>
</dd></dl>

</section>
</dd></dl>

</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="omv.image.html" class="btn btn-neutral float-left" title="image — machine vision" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="omv.ml.apps.html" class="btn btn-neutral float-right" title="ml.apps — ML Apps" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright - The MicroPython Documentation is Copyright © 2014-2025, Damien P. George, Paul Sokolovsky, and contributors.
      <span class="lastupdated">Last updated on 01 Feb 2025.
      </span></p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    <span class="fa fa-book"> Language and External Links</span>
    <span class="fa fa-caret-down"></span>
  </span>
  <div class="rst-other-versions">
    <dl>
      <dt>Language</dt>
      <dd>
        <a href="https://openmv.io">English</a>
      </dd>
      <dd>
        <a href="http://doc.singtown.cc">中文</a>
      </dd>
    </dl>
    <hr/>
    <dl>
      <dt>External links</dt>
      <dd>
        <a href="https://openmv.io">openmv.io</a>
      </dd>
      <dd>
        <a href="http://forums.openmv.io">forums.openmv.io</a>
      </dd>
      <dd>
        <a href="https://github.com/openmv/openmv">github.com/openmv/openmv</a>
      </dd>
      <dd>
        <a href="http://micropython.org">micropython.org</a>
      </dd>
      <dd>
        <a href="http://forum.micropython.org">forum.micropython.org</a>
      </dd>
      <dd>
        <a href="https://github.com/micropython/micropython">github.com/micropython/micropython</a>
      </dd>
    </dl>
  </div>
</div><script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>